{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center Cut Prediction Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby, chain\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from skimage import io, color\n",
    "import sys\n",
    "from skimage import img_as_ubyte\n",
    "import skimage.io as io\n",
    "import os\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commong Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, pad=True):\n",
    "    \"\"\"\n",
    "    Load image from a given path and pad it on the sides, so that eash side is divisible by 32 (newtwork requirement)\n",
    "    \n",
    "    if pad = True:\n",
    "        returns image as numpy.array, tuple with padding in pixels as(x_min_pad, y_min_pad, x_max_pad, y_max_pad)\n",
    "    else:\n",
    "        returns image as numpy.array\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if not pad:\n",
    "        return img\n",
    "    \n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    if height % 32 == 0:\n",
    "        y_min_pad = 0\n",
    "        y_max_pad = 0\n",
    "    else:\n",
    "        y_pad = 32 - height % 32\n",
    "        y_min_pad = int(y_pad / 2)\n",
    "        y_max_pad = y_pad - y_min_pad\n",
    "        \n",
    "    if width % 32 == 0:\n",
    "        x_min_pad = 0\n",
    "        x_max_pad = 0\n",
    "    else:\n",
    "        x_pad = 32 - width % 32\n",
    "        x_min_pad = int(x_pad / 2)\n",
    "        x_max_pad = x_pad - x_min_pad\n",
    "    \n",
    "    img = cv2.copyMakeBorder(img, y_min_pad, y_max_pad, x_min_pad, x_max_pad, cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    return img, (x_min_pad, y_min_pad, x_max_pad, y_max_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #from utilities.model_errors import ValidationError\n",
    "\n",
    "\n",
    "# def find_centermost_mask(input_mask, min_pixels):\n",
    "#     \"\"\"\n",
    "#     Take in a binary mask and return a mask of the same shape, with only the centermost contiguous portion.\n",
    "#     If a mask contains no contours (objects), then just return it (it's all zeros anyway).\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Get all the bits aligned in memory\n",
    "#     input_mask = np.ascontiguousarray(input_mask, dtype=np.uint8)\n",
    "#     contours, _ = cv2.findContours(input_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     print('no. of contours : ', len(contours))\n",
    "    \n",
    "#     if not contours or len(contours) == 1:\n",
    "#         return input_mask\n",
    "\n",
    "#     moments = [cv2.moments(contour) for contour in contours]\n",
    "#     # (x, y) tuples of centroid locations for contours (that have area > 0)\n",
    "#     centroids = [\n",
    "#         (m['m10'] / m['m00'], m['m01'] / m['m00'])\n",
    "#         if m['m00'] and m['m00'] >= min_pixels else (0, 0)\n",
    "#         for m in moments\n",
    "#     ]\n",
    "\n",
    "#     if not centroids:\n",
    "#         raise ValidationError(f'No identified footprint contours contain more than {min_pixels} pixels.')\n",
    "\n",
    "#     # dimensions come 1-indexed, but array indicies are 0-indexed\n",
    "#     center = [(dim - 1) / 2 for dim in input_mask.shape]\n",
    "\n",
    "#     # Cacluate (Manhattan) distance from center of image\n",
    "#     distances_from_center = [abs(x - center[0]) + abs(y - center[1]) for x, y in centroids]\n",
    "#     centermost_contour = contours[distances_from_center.index(min(distances_from_center))]\n",
    "\n",
    "#     output_mask = np.zeros(input_mask.shape)\n",
    "#     cv2.fillPoly(output_mask, centermost_contour.transpose((1, 0, 2)), 1)\n",
    "\n",
    "#     return output_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centermost_mask(input_mask, min_pixels):\n",
    "    \"\"\"\n",
    "    Take in a binary mask and return a mask of the same shape, with only the centermost contiguous portion.\n",
    "    If a mask contains no contours (objects), then just return it (it's all zeros anyway).\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all the bits aligned in memory\n",
    "    input_mask = np.ascontiguousarray(input_mask, dtype=np.uint8)\n",
    "    print(input_mask.shape, np.sum(input_mask))\n",
    "    contours, _ = cv2.findContours(input_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(len(contours))\n",
    "\n",
    "    if not contours or len(contours) == 1:\n",
    "        return input_mask\n",
    "\n",
    "    moments = [cv2.moments(contour) for contour in contours]\n",
    "    # (x, y) tuples of centroid locations for contours (that have area > 0)\n",
    "    centroids = [\n",
    "        (m['m10'] / m['m00'], m['m01'] / m['m00'])\n",
    "        if m['m00'] and m['m00'] >= min_pixels else (0, 0)\n",
    "        for m in moments\n",
    "    ]\n",
    "\n",
    "    if not centroids:\n",
    "        raise ValidationError(f'No identified footprint contours contain more than {min_pixels} pixels.')\n",
    "\n",
    "    # dimensions come 1-indexed, but array indicies are 0-indexed\n",
    "    center = [(dim - 1) / 2 for dim in input_mask.shape]\n",
    "\n",
    "    # Cacluate (Manhattan) distance from center of image\n",
    "    distances_from_center = [abs(x - center[0]) + abs(y - center[1]) for x, y in centroids]\n",
    "    centermost_contour = contours[distances_from_center.index(min(distances_from_center))]\n",
    "\n",
    "    output_mask = np.zeros(input_mask.shape)\n",
    "    cv2.fillPoly(output_mask, centermost_contour.transpose((1, 0, 2)), 1)\n",
    "\n",
    "    return output_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center cut the Prediction Image and Center Cut the Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_binary_img_path = '/home/ec2-user/SageMaker/data/footprint/mohan-func-test-run-data/run-1/resnet-50-out'\n",
    "pred_cc_save_path = '/home/ec2-user/SageMaker/data/footprint/mohan-func-test-run-data/run-1/rn50-cc-analysis'\n",
    "\n",
    "# pred_binary_img_path = '/home/ec2-user/SageMaker/data/footprint/190-test-images-pred-analysis-rn50-9-jan-2k20/190-test-images-pred-ouput-RGB-rn50-3-jan-2k20'\n",
    "# pred_cc_save_path = '/home/ec2-user/SageMaker/data/footprint/190-test-images-pred-analysis-rn50-9-jan-2k20/190-test-pred-images-cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['image_427_pred_binary.png',\n",
       "  'image_489_pred_binary.png',\n",
       "  'image_99_pred_binary.png',\n",
       "  'image_40_pred_binary.png',\n",
       "  'image_359_pred_binary.png'],\n",
       " 627)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_pred_imgs = [img for img in os.listdir(pred_binary_img_path) if os.path.isfile(os.path.join(pred_binary_img_path, img))]\n",
    "lst_pred_imgs[:5], len(lst_pred_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(pred_prob, threshold=0.6):\n",
    "    '''\n",
    "    generate the mask if the probability is 60%\n",
    "    '''\n",
    "    mask = pred_prob[0, :, :, :]\n",
    "    pred_mask = np.argmax(mask.transpose((1, 2, 0)), axis=-1)\n",
    "    return pred_mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_583_pred_binary.png',\n",
       " 'image_493_pred_binary.png',\n",
       " 'image_131_pred_binary.png']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_pred_imgs[7:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for idx, pred_img_name in enumerate(lst_pred_imgs[7:10], start=1):\n",
    "    \n",
    "#     print('processing : ', idx)\n",
    "#     pred_img_path_with_filename = os.path.join(pred_binary_img_path, pred_img_name)\n",
    "#     pred_img = cv2.imread(pred_img_path_with_filename)\n",
    "#     pred_gray = cv2.cvtColor(pred_img, cv2.COLOR_BGR2GRAY)\n",
    "#     print(np.unique(pred_gray))\n",
    "#     plt.imshow(pred_gray)\n",
    "#     plt.show()\n",
    "    \n",
    "# #     pred_gray[pred_gray > 30] = 1\n",
    "# #     pred_gray[pred_gray < 30] = 0\n",
    "    \n",
    "# #----------------------    \n",
    "#     unique_pixel_values = np.unique(pred_gray)\n",
    "#     if(len(unique_pixel_values) > 1):  # to handle no building scenario returns one pixel value that is '0'\n",
    "#         _, thresh = cv2.threshold(pred_gray, unique_pixel_values[0] + 1, 255, 0)\n",
    "#         print(np.unique(thresh))\n",
    "#         pred_cc_img_mask=find_centermost_mask(thresh,2000)\n",
    "#     else:\n",
    "#         pred_cc_img_mask = np.zeros(pred_gray.shape)\n",
    "# #     print(np.unique(lbl_cc_img_mask))\n",
    "# #     print(lbl_cc_img_mask.shape)\n",
    "# #----------------------    \n",
    "    \n",
    "# #     pred_cc_img_mask=find_centermost_mask(pred_gray,10000)\n",
    "#     print('cc unique', np.unique(pred_cc_img_mask))\n",
    "# #     print(type(pred_cc_img_mask))\n",
    "# #     print(pred_cc_img_mask.dtype)\n",
    "#     pred_cc_img_mask = pred_cc_img_mask.astype(np.byte)\n",
    "#     pred_cc_img_mask = img_as_ubyte(pred_cc_img_mask)\n",
    "# #     print(pred_cc_img_mask.dtype)\n",
    "# #     print(np.unique(pred_cc_img_mask))\n",
    "#     print('cc shape', pred_cc_img_mask.shape)\n",
    "#     plt.imshow(pred_cc_img_mask)\n",
    "#     plt.show()\n",
    "# #     io.imsave(os.path.join(pred_cc_save_path, pred_img_name.replace('_pred_binary.png', '_pred_cc_binary.tif')), pred_cc_img_mask)\n",
    "#     print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, pred_img_name in enumerate(lst_pred_imgs[7:10], start=1):\n",
    "    \n",
    "    print('processing : ', idx)\n",
    "    pred_img_path_with_filename = os.path.join(pred_binary_img_path, pred_img_name)\n",
    "    pred_img = cv2.imread(pred_img_path_with_filename)\n",
    "#     pred_gray = cv2.cvtColor(pred_img, cv2.COLOR_BGR2GRAY)\n",
    "    pred_gray = io.imread(pred_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    print(np.unique(pred_gray))\n",
    "    plt.imshow(pred_gray)\n",
    "    plt.show()\n",
    "\n",
    "#----------------------    \n",
    "    unique_pixel_values = np.unique(pred_gray)\n",
    "    if(len(unique_pixel_values) > 1):  # to handle no building scenario returns one pixel value that is '0'\n",
    "        _, thresh = cv2.threshold(pred_gray, unique_pixel_values[0] + 1, 255, 0)\n",
    "        print(np.unique(thresh))\n",
    "        pred_cc_img_mask=find_centermost_mask(thresh,2000)\n",
    "    else:\n",
    "        pred_cc_img_mask = np.zeros(pred_gray.shape)\n",
    "#     print(np.unique(lbl_cc_img_mask))\n",
    "#     print(lbl_cc_img_mask.shape)\n",
    "#----------------------    \n",
    "    \n",
    "#     pred_cc_img_mask=find_centermost_mask(pred_gray,10000)\n",
    "    print('cc unique', np.unique(pred_cc_img_mask))\n",
    "#     print(type(pred_cc_img_mask))\n",
    "#     print(pred_cc_img_mask.dtype)\n",
    "    pred_cc_img_mask = pred_cc_img_mask.astype(np.byte)\n",
    "    pred_cc_img_mask = img_as_ubyte(pred_cc_img_mask)\n",
    "#     print(pred_cc_img_mask.dtype)\n",
    "#     print(np.unique(pred_cc_img_mask))\n",
    "    print('cc shape', pred_cc_img_mask.shape)\n",
    "    plt.imshow(pred_cc_img_mask)\n",
    "    plt.show()\n",
    "#     io.imsave(os.path.join(pred_cc_save_path, pred_img_name.replace('_pred_binary.png', '_pred_cc_binary.tif')), pred_cc_img_mask)\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gray = io.imread('/home/ec2-user/SageMaker/data/footprint/mohan-func-test-run-data/run-1/resnet-50-out/image_493_pred_binary.png')[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68, 253], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gray[pred_gray == 68] = 0\n",
    "pred_gray[pred_gray == 253] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8c5e8c54a8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pixel_values = np.unique(pred_gray)\n",
    "_, thresh = cv2.threshold(pred_gray, unique_pixel_values[0] + 1, 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512) 74863\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "center_prop = find_centermost_mask(pred_gray,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8c5e31f438>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(center_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10012\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ec2-user/SageMaker/data/footprint/10009-training-images/input/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10009\r\n"
     ]
    }
   ],
   "source": [
    "! ls /home/ec2-user/SageMaker/data/footprint/10009-training-images/gt-binary/ | wc -l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_fastai",
   "language": "python",
   "name": "conda_fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
